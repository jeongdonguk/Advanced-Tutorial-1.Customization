{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyNp9uKmbtbvdJxgWzXYowXX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"1LI4Ly7b-eQl","executionInfo":{"status":"ok","timestamp":1674915607173,"user_tz":-540,"elapsed":2846,"user":{"displayName":"화정이네","userId":"05305307080143119231"}}},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"markdown","source":["### Tensor\n","텐서는 다차원 배열입니다. numpy의 배열과 유사하게 tf.Tensor객체에는 데이터 유형과 모양이 있습니다. tf.Tensor는 GPU와 같은 가속기 메모리에 상주할 수 있습니다. Tensorflow는 tf.Tensor를 소비하고 생성하는 풍부한 연산 라이브러리를 제공합니다.(tf.math.add(덧셈), tf.linalg.matmul(행렬곱), tf.linalg.inv(역행렬) 등). 이러한 연산은 기본 python 유형을 자동으로 변환합니다."],"metadata":{"id":"8hZdRgGcCfUK"}},{"cell_type":"code","source":["print(tf.math.add(1,2))\n","print(tf.math.add([1,2],[3,4]))\n","print(tf.math.square(5))\n","print(tf.math.reduce_sum([1,2,3]))\n","print(tf.math.reduce_sum([[1,2,3],[1,2,5]]))\n","print(tf.math.square(2) + tf.math.square(3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UM_aEU1oDZmP","executionInfo":{"status":"ok","timestamp":1674915607614,"user_tz":-540,"elapsed":443,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"d9e55846-94a3-4577-c181-8e26e8d26a38"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(3, shape=(), dtype=int32)\n","tf.Tensor([4 6], shape=(2,), dtype=int32)\n","tf.Tensor(25, shape=(), dtype=int32)\n","tf.Tensor(6, shape=(), dtype=int32)\n","tf.Tensor(14, shape=(), dtype=int32)\n","tf.Tensor(13, shape=(), dtype=int32)\n"]}]},{"cell_type":"code","source":["x = tf.linalg.matmul([[2]],[[2,3]])\n","print(x)\n","print(x.shape)\n","print(x.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cio6QnHyEuvz","executionInfo":{"status":"ok","timestamp":1674915607615,"user_tz":-540,"elapsed":5,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"4a589595-8f63-4f2c-e2b8-d14566483570"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([[4 6]], shape=(1, 2), dtype=int32)\n","(1, 2)\n","<dtype: 'int32'>\n"]}]},{"cell_type":"markdown","source":["### tf.Tensor의 장점\n"," - 텐서플로 연산은 자동으로 numpy배열을 텐서로 변환합니다.\n"," - numpy연산은 자동으로 텐서를 numpy배열로 변환합니다.\n"," - 텐서는 .numpy() 메서드를 통해 numpy배열로 변환이 가능합니다. 그러나 tf.Tensor는 GPU 메모리에 저장될 수 있고, numpy 배열은 항상 호스트 메모리에 저장되므로, 이러한 변환이 항상 가능한 것은 아닙니다. 따라서 gpu에서 호스트 메모리로 복사가 필요합니다."],"metadata":{"id":"_2yJxNiCMH4g"}},{"cell_type":"code","source":["import numpy as np\n","\n","ndarray = np.ones([3,3])\n","print('ndarray : \\n',ndarray)\n","tensor = tf.math.multiply(ndarray, 42)\n","print('tensor : \\n',tensor)\n","# 자동으로 텐서가 넘파이 배열화 되어 연산됨을 확인해본다.\n","print('\\n',np.add(tensor,1))\n","# 매서드를 통한 넘파이와 텐서간의 변화를 확인해본다.\n","print('\\n',tensor.numpy())"],"metadata":{"id":"7hZyiATDPDqN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674915607615,"user_tz":-540,"elapsed":4,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"82e1a9ef-b5ae-4807-8694-f710d3bf4d5e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["ndarray : \n"," [[1. 1. 1.]\n"," [1. 1. 1.]\n"," [1. 1. 1.]]\n","tensor : \n"," tf.Tensor(\n","[[42. 42. 42.]\n"," [42. 42. 42.]\n"," [42. 42. 42.]], shape=(3, 3), dtype=float64)\n","\n"," [[43. 43. 43.]\n"," [43. 43. 43.]\n"," [43. 43. 43.]]\n","\n"," [[42. 42. 42.]\n"," [42. 42. 42.]\n"," [42. 42. 42.]]\n"]}]},{"cell_type":"markdown","source":["## GPU 가속\n"," 대부분의 텐서 연산은 GPU를 사용하여 가속한다. 따로 코드를 명시하지 않아도 tensorflow는 연산을 위해 CPU or GPU의 사용을 자동으로 결정한다. 필요시 둘 사이의 메모리에서 복사되기도 합니다. 연산에 의해 생성된 텐서는 연산이 실행된 장치의 메모리에 의해 실행됩니다.\n"," <br>예시는 아래와 같습니다"],"metadata":{"id":"gOiPGw6pfI46"}},{"cell_type":"code","source":["x = tf.random.uniform([3,3])\n","print(x)\n","\n","print('GPU장치가 있는지 확인해본다.')\n","print(tf.config.list_physical_devices())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZQvKQbdqhNxM","executionInfo":{"status":"ok","timestamp":1674915607616,"user_tz":-540,"elapsed":4,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"4cd8e874-c53a-4392-b655-01770e557aac"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[0.12367165 0.35694635 0.618688  ]\n"," [0.80290425 0.26262748 0.6492804 ]\n"," [0.72215164 0.09392834 0.2733034 ]], shape=(3, 3), dtype=float32)\n","GPU장치가 있는지 확인해본다.\n","[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"]}]},{"cell_type":"markdown","source":["### 위의 방식으로 확인해보면 GPU가 없음을 알 수 있다. 필자는 구글의 코랩 유료버전을 사용중이므로 TPU를 이용할 것이며 TPU에 대한 확인과 사용방법은 아래와 같다."],"metadata":{"id":"badhZLZehrLj"}},{"cell_type":"code","source":["import os\n","x = tf.random.uniform([3,3])\n","print(x)\n","# 현재 검색가능한 디바이스 검색\n","print(tf.config.list_physical_devices())\n","print('TPU장치가 있는지 확인해본다.')\n","print(os.environ['COLAB_TPU_ADDR'])\n","# tpu이름을 통해 해당 장치를 지정하여 사용이 가능한데 나의 tpu이름은 아래와 같이 사용하면 된다.\n","tpu_name = 'grpc://'+os.environ['COLAB_TPU_ADDR']\n","print('tpu_name : ',tpu_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Mje8zRqk65q","executionInfo":{"status":"ok","timestamp":1674915611252,"user_tz":-540,"elapsed":3,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"b2c22778-4431-4ca5-bce3-5fc229e137cf"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[0.64974487 0.24309683 0.0386498 ]\n"," [0.79751897 0.59210503 0.4541067 ]\n"," [0.00106108 0.7817106  0.78778374]], shape=(3, 3), dtype=float32)\n","[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n","TPU장치가 있는지 확인해본다.\n","10.88.69.138:8470\n","tpu_name :  grpc://10.88.69.138:8470\n"]}]},{"cell_type":"markdown","source":["TPU와 CPU의 성능 차이를 비교해 보겠다.<br>\n","CPU 사용법"],"metadata":{"id":"FDf1fZzblHxJ"}},{"cell_type":"code","source":["%%time\n","print('on cpu:')\n","with tf.device('CPU:0'):\n","    x = tf.random.uniform([1000, 1000])\n","    assert x.device.endswith('CPU:0')\n","    for i in range(100):\n","        tf.linalg.matmul(x,x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xabg7nNOv8d8","executionInfo":{"status":"ok","timestamp":1674915618928,"user_tz":-540,"elapsed":267,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"97e1d727-07d7-4559-e7e7-7d07900ac863"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["on cpu:\n","CPU times: user 6.58 s, sys: 65.2 ms, total: 6.64 s\n","Wall time: 199 ms\n"]}]},{"cell_type":"markdown","source":["### TPU사용법"],"metadata":{"id":"VJGSKuiTw21g"}},{"cell_type":"code","source":["# tpu 사용준비\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_name)\n","\n","tf.config.experimental_connect_to_cluster(resolver)\n","tf.tpu.experimental.initialize_tpu_system(resolver)"],"metadata":{"id":"J1sZ8xTcnPdM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1674915845091,"user_tz":-540,"elapsed":13726,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"b47c82c6-cff8-4e32-d22f-f110e1f41eeb"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.tpu.topology.Topology at 0x7f1fd6626580>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["strategy = tf.distribute.TPUStrategy(resolver)"],"metadata":{"id":"y2_9Uku3rDfv","executionInfo":{"status":"ok","timestamp":1674915855532,"user_tz":-540,"elapsed":250,"user":{"displayName":"화정이네","userId":"05305307080143119231"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### 텐서플로우의 경우 자동적으로 장치를 할당하지만 아래와 같이 명시적으로 사용하여 장치를 사용할 수 있습니다."],"metadata":{"id":"rh-IbjzQuadK"}},{"cell_type":"code","source":["%%time\n","print('on TPU:')\n","with strategy.scope():\n","    x = tf.random.uniform([1000, 1000])\n","    for i in range(100):\n","        tf.linalg.matmul(x,x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJLbPlbHvXKQ","executionInfo":{"status":"ok","timestamp":1674915881392,"user_tz":-540,"elapsed":238,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"d6e6d46f-4ede-45eb-b254-cc84c20b49a8"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["on TPU:\n","CPU times: user 10.9 ms, sys: 7.47 ms, total: 18.4 ms\n","Wall time: 15.7 ms\n"]}]},{"cell_type":"markdown","source":["#### 위를 보면 알 수 있듯이 실제 실행시간이(wall time) tpu를 사용한 경우 많이 줄어들었음을 알 수 있다."],"metadata":{"id":"m2nB12NuvdQz"}},{"cell_type":"markdown","source":["### tf.data.Dataset.from_tensor_slices 에 대해 알아보자\n","주어진 텐서는 첫번째 차원을 따라 슬라이스 된다. 이작업은 입력텐서의 구조를 유지하며 각 텐서의 첫번째 차원을 데이터셋 차원으로 사용한다."],"metadata":{"id":"k-RrTu5bxOXU"}},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices([1,2,3])\n","a = dataset.as_numpy_iterator()\n","for i in a:\n","    print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27nhkVVaGnWa","executionInfo":{"status":"ok","timestamp":1674921987188,"user_tz":-540,"elapsed":350,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"40f7ae6e-e41e-4c6b-c647-bbbf32e59ffd"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function Executor.__del__ at 0x7f20f0c140d0>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n","    self.wait()\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n","    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n","tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n"]},{"output_type":"stream","name":"stdout","text":["1\n","2\n","3\n"]}]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices([[1,2],[3,4],[5,6]])\n","a = dataset.as_numpy_iterator()\n","for i in a:\n","    print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L3UnY9WUHUy4","executionInfo":{"status":"ok","timestamp":1674922071693,"user_tz":-540,"elapsed":2,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"9fdd1a8b-39bb-412c-8fc7-6f41695ebb08"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function Executor.__del__ at 0x7f20f0c140d0>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n","    self.wait()\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n","    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n","tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n"]},{"output_type":"stream","name":"stdout","text":["[1 2]\n","[3 4]\n","[5 6]\n"]}]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices(([1,2],[3,4],[5,6]))\n","a = dataset.as_numpy_iterator()\n","for i in a:\n","    print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Dcpwli5HnO5","executionInfo":{"status":"ok","timestamp":1674922060461,"user_tz":-540,"elapsed":2,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"14d76afd-2f57-422d-db5c-0cd825f08130"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function Executor.__del__ at 0x7f20f0c140d0>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n","    self.wait()\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n","    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n","tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n"]},{"output_type":"stream","name":"stdout","text":["(1, 3, 5)\n","(2, 4, 6)\n"]}]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices({'a':[1,2],'b':[3,4],'c':[5,6]})\n","a = dataset.as_numpy_iterator()\n","for i in a:\n","    print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVZ1k5ICIW7x","executionInfo":{"status":"ok","timestamp":1674922126711,"user_tz":-540,"elapsed":2,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"b4f28a34-f2ae-4f04-f459-5948c46ccc19"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function Executor.__del__ at 0x7f20f0c140d0>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/executor.py\", line 46, in __del__\n","    self.wait()\n","  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/executor.py\", line 65, in wait\n","    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)\n","tensorflow.python.framework.errors_impl.OutOfRangeError: End of sequence\n"]},{"output_type":"stream","name":"stdout","text":["{'a': 1, 'b': 3, 'c': 5}\n","{'a': 2, 'b': 4, 'c': 6}\n"]}]},{"cell_type":"code","source":["tf.constant([[[1, 2], [3, 4]],\n","            [[5, 6], [7, 8]],\n","            [[9, 10], [11, 12]]], shape=(12))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gyhXXZUyI2oh","executionInfo":{"status":"ok","timestamp":1674922415318,"user_tz":-540,"elapsed":250,"user":{"displayName":"화정이네","userId":"05305307080143119231"}},"outputId":"689335ff-2568-4760-b47b-294be5b63ea9"},"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int32)>"]},"metadata":{},"execution_count":45}]}]}